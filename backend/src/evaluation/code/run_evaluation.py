"""
ì„±ëŠ¥ ì¸¡ì • ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Phase 1: Baseline (í˜„ì¬ ì‹œìŠ¤í…œ)
Phase 2: With RAG (RAG DB ì ìš© í›„)

ì‚¬ìš©ë²•:
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    python run_evaluation.py --generate-data

    # Phase 1 ì¸¡ì • (5ê°œë§Œ í…ŒìŠ¤íŠ¸)
    python run_evaluation.py --phase phase1_baseline --limit 5

    # Phase 1 ì¸¡ì • (ì „ì²´)
    python run_evaluation.py --phase phase1_baseline

    # Phase ë¹„êµ
    python run_evaluation.py --compare
"""

import json
import sys
import os
import argparse
import requests
import psycopg2
import time
from psycopg2.extras import RealDictCursor
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# ê²½ë¡œ ì„¤ì •
EVAL_DIR = Path(__file__).parent.parent
DATA_DIR = EVAL_DIR / "data"
RESULTS_DIR = EVAL_DIR / "results"
REPORTS_DIR = EVAL_DIR / "reports"

# í‰ê°€ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.insert(0, str(Path(__file__).parent))
from performance_evaluator import PerformanceEvaluator, evaluator
from dataset_generator import dataset_generator

# í…ŒìŠ¤íŠ¸ìš© ID ì‹œì‘ ë²ˆí˜¸ (ê¸°ì¡´ ë°ì´í„°ì™€ ì¶©ëŒ ë°©ì§€)
TEST_ID_START = 90000


class TestDatabaseManager:
    """í…ŒìŠ¤íŠ¸ìš© DB ê´€ë¦¬ì (ì§ì ‘ ì—°ê²°)"""

    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš© (MY_POSTGRES_* í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
        self.host = os.getenv("MY_POSTGRES_HOST", os.getenv("POSTGRES_HOST", "localhost"))
        self.database = os.getenv("MY_POSTGRES_DB", os.getenv("POSTGRES_DB", "mail"))
        self.user = os.getenv("MY_POSTGRES_USER", os.getenv("POSTGRES_USER", "admin"))
        self.password = os.getenv("MY_POSTGRES_PASSWORD", os.getenv("POSTGRES_PASSWORD", "1234"))
        self.port = int(os.getenv("MY_POSTGRES_PORT", os.getenv("POSTGRES_PORT", "5432")))

    def get_connection(self):
        """PostgreSQL ì—°ê²°"""
        return psycopg2.connect(
            host=self.host,
            database=self.database,
            user=self.user,
            password=self.password,
            port=self.port,
            cursor_factory=RealDictCursor
        )

    def insert_test_emails(self, emails: List[Dict]) -> List[int]:
        """í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ë“¤ì„ DBì— ì‚½ì…"""
        conn = self.get_connection()
        cur = conn.cursor()
        inserted_ids = []

        try:
            for i, email in enumerate(emails):
                # synthetic_001 -> 90001 í˜•ì‹ìœ¼ë¡œ ID ë³€í™˜
                test_id = TEST_ID_START + i + 1

                cur.execute("""
                    INSERT INTO email
                    (id, subject, sender_name, sender_address, body_text, received_at, original_uid, is_replied_to)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, FALSE)
                    ON CONFLICT (id) DO UPDATE SET
                        subject = EXCLUDED.subject,
                        sender_name = EXCLUDED.sender_name,
                        sender_address = EXCLUDED.sender_address,
                        body_text = EXCLUDED.body_text,
                        received_at = EXCLUDED.received_at,
                        email_type = NULL,
                        importance_score = NULL,
                        needs_reply = NULL,
                        sentiment = NULL,
                        ai_analysis = NULL,
                        processing_status = NULL
                    RETURNING id
                """, (
                    test_id,
                    email.get('subject'),
                    email.get('sender_name'),
                    email.get('sender_address'),
                    email.get('body_text'),
                    email.get('received_at', datetime.now().isoformat()),
                    f"test_{email.get('id')}",
                ))
                result = cur.fetchone()
                inserted_ids.append(result['id'])

            conn.commit()
            print(f"âœ… {len(inserted_ids)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ DB ì‚½ì… ì™„ë£Œ")
            return inserted_ids

        except Exception as e:
            conn.rollback()
            raise e
        finally:
            cur.close()
            conn.close()

    def delete_test_emails(self, email_ids: List[int]) -> int:
        """í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì‚­ì œ"""
        if not email_ids:
            return 0

        conn = self.get_connection()
        cur = conn.cursor()

        try:
            # ê´€ë ¨ reply_drafts ë¨¼ì € ì‚­ì œ
            cur.execute("""
                DELETE FROM reply_drafts
                WHERE email_id = ANY(%s)
            """, (email_ids,))

            # ì´ë©”ì¼ ì‚­ì œ
            cur.execute("""
                DELETE FROM email
                WHERE id = ANY(%s)
                RETURNING id
            """, (email_ids,))
            deleted = cur.fetchall()
            conn.commit()
            print(f"ğŸ—‘ï¸ {len(deleted)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì‚­ì œ ì™„ë£Œ")
            return len(deleted)

        except Exception as e:
            conn.rollback()
            raise e
        finally:
            cur.close()
            conn.close()

    def cleanup_all_test_emails(self) -> int:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì‚­ì œ (ID >= TEST_ID_START)"""
        conn = self.get_connection()
        cur = conn.cursor()

        try:
            # ê´€ë ¨ reply_drafts ë¨¼ì € ì‚­ì œ
            cur.execute("""
                DELETE FROM reply_drafts
                WHERE email_id >= %s
            """, (TEST_ID_START,))

            # í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì‚­ì œ
            cur.execute("""
                DELETE FROM email
                WHERE id >= %s
                RETURNING id
            """, (TEST_ID_START,))
            deleted = cur.fetchall()
            conn.commit()
            print(f"ğŸ—‘ï¸ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ì‚­ì œ ì™„ë£Œ: {len(deleted)}ê°œ")
            return len(deleted)

        except Exception as e:
            conn.rollback()
            raise e
        finally:
            cur.close()
            conn.close()


class EvaluationRunner:
    """ì„±ëŠ¥ ì¸¡ì • ì‹¤í–‰ê¸°"""

    # ë¬¸ì œê°€ ë˜ëŠ” íŠ¹ìˆ˜ë¬¸ì ë§¤í•‘ (n8n JSON íŒŒì‹± í˜¸í™˜ì„±)
    SPECIAL_CHAR_MAP = {
        'Â·': '-',      # middle dot -> hyphen
        'â€“': '-',      # en dash -> hyphen
        'â€”': '-',      # em dash -> hyphen
        ''': "'",      # fancy single quote -> simple quote
        ''': "'",      # fancy single quote -> simple quote
        '"': '"',      # fancy double quote -> simple quote
        '"': '"',      # fancy double quote -> simple quote
        'â€¦': '...',    # ellipsis -> three dots
        '\r\n': '\n',  # Windows line ending -> Unix
        '\r': '\n',    # old Mac line ending -> Unix
    }

    def __init__(self, phase: str = "phase1_baseline", n8n_url: str = None):
        # n8n URL í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš© (Docker ë„¤íŠ¸ì›Œí¬ ë‚´ì—ì„œëŠ” n8n ì»¨í…Œì´ë„ˆ ì´ë¦„ ì‚¬ìš©)
        if n8n_url is None:
            n8n_url = os.getenv("N8N_URL", "http://n8n:5678")
        self.phase = phase
        self.n8n_url = n8n_url
        self.evaluator = PerformanceEvaluator()
        self.db_manager = TestDatabaseManager()

        self.test_email_ids = []  # ì‚½ì…ëœ í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ID ì¶”ì 
        self.id_mapping = {}  # synthetic_id -> db_id ë§¤í•‘
        self.results = {
            "phase": phase,
            "started_at": datetime.now().isoformat(),
            "n8n_url": n8n_url,
            "analysis_results": [],
            "reply_results": [],
            "errors": []
        }

    def sanitize_text(self, text: str) -> str:
        """n8n JSON íŒŒì‹± í˜¸í™˜ì„±ì„ ìœ„í•œ íŠ¹ìˆ˜ë¬¸ì ì •ì œ"""
        if not text:
            return text
        for char, replacement in self.SPECIAL_CHAR_MAP.items():
            text = text.replace(char, replacement)
        return text

    def load_test_data(self) -> Dict:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        dataset_path = DATA_DIR / "test_dataset.json"

        if not dataset_path.exists():
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...")
            dataset_generator.save_test_dataset()
            dataset_generator.save_ground_truth()

        with open(dataset_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def load_ground_truth(self) -> Dict:
        """Ground Truth ë¡œë“œ"""
        gt_path = DATA_DIR / "ground_truth.json"

        with open(gt_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            return {gt["id"]: gt for gt in data["ground_truths"]}

    def setup_test_data(self, emails: List[Dict]) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ DBì— ì‚½ì…í•˜ê³  ID ë§¤í•‘ ìƒì„±"""
        print("\nğŸ“¥ í…ŒìŠ¤íŠ¸ ë°ì´í„° DB ì‚½ì… ì¤‘...")

        # DBì— ì‚½ì…
        self.test_email_ids = self.db_manager.insert_test_emails(emails)

        # ID ë§¤í•‘ ìƒì„± (synthetic_001 -> 90001)
        for i, email in enumerate(emails):
            db_id = self.test_email_ids[i]
            self.id_mapping[email["id"]] = db_id
            # ì´ë©”ì¼ ë°ì´í„°ì— ì‹¤ì œ DB ID ì¶”ê°€
            email["db_id"] = db_id

        print(f"ğŸ“Š ID ë§¤í•‘: {len(self.id_mapping)}ê°œ")
        return emails

    def cleanup_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬"""
        if self.test_email_ids:
            print("\nğŸ§¹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì¤‘...")
            self.db_manager.delete_test_emails(self.test_email_ids)
            self.test_email_ids = []
            self.id_mapping = {}

    def call_analyze_api(self, email_data: Dict) -> Optional[Dict]:
        """n8n analyze webhook í˜¸ì¶œ (ì‹¤ì œ DB ID ì‚¬ìš©)"""
        try:
            webhook_url = f"{self.n8n_url}/webhook/analyze"

            # ì‹¤ì œ DB ID ì‚¬ìš©
            db_id = email_data.get("db_id", email_data["id"])

            # íŠ¹ìˆ˜ë¬¸ì ì •ì œ ì ìš©
            payload = {
                "email_id": db_id,
                "subject": self.sanitize_text(email_data["subject"]),
                "sender_name": self.sanitize_text(email_data["sender_name"]),
                "sender_address": email_data["sender_address"],
                "body_text": self.sanitize_text(email_data["body_text"])
            }

            # ëª…ì‹œì ìœ¼ë¡œ UTF-8 ì¸ì½”ë”© ë° Content-Type ì„¤ì •
            headers = {'Content-Type': 'application/json; charset=utf-8'}
            response = requests.post(
                webhook_url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers=headers,
                timeout=60
            )

            if response.status_code == 200:
                # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
                if not response.text or response.text.strip() == '':
                    print(f"  [ERROR] ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                    return None
                return response.json()
            else:
                print(f"  [ERROR] ë¶„ì„ ì‹¤íŒ¨: {response.status_code} - {response.text[:100]}")
                return None

        except requests.exceptions.Timeout:
            print(f"  [ERROR] íƒ€ì„ì•„ì›ƒ: {email_data['id']}")
            return None
        except json.JSONDecodeError as e:
            print(f"  [ERROR] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            print(f"  [ERROR] ì˜ˆì™¸: {e}")
            return None

    def call_reply_api(self, email_data: Dict, tone: str = "formal") -> Optional[Dict]:
        """n8n generate-reply webhook í˜¸ì¶œ"""
        try:
            webhook_url = f"{self.n8n_url}/webhook/generate-reply"

            # ì‹¤ì œ DB ID ì‚¬ìš©
            db_id = email_data.get("db_id", email_data["id"])

            # íŠ¹ìˆ˜ë¬¸ì ì •ì œ ì ìš©
            payload = {
                "email_id": db_id,
                "subject": self.sanitize_text(email_data["subject"]),
                "sender_name": self.sanitize_text(email_data["sender_name"]),
                "sender_address": email_data["sender_address"],
                "body_text": self.sanitize_text(email_data["body_text"]),
                "preferred_tone": tone
            }

            # ëª…ì‹œì ìœ¼ë¡œ UTF-8 ì¸ì½”ë”© ë° Content-Type ì„¤ì •
            headers = {'Content-Type': 'application/json; charset=utf-8'}
            response = requests.post(
                webhook_url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers=headers,
                timeout=90
            )

            if response.status_code == 200:
                # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
                if not response.text or response.text.strip() == '':
                    print(f"  [ERROR] ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                    return None
                return response.json()
            else:
                print(f"  [ERROR] ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {response.status_code}")
                return None

        except json.JSONDecodeError as e:
            print(f"  [ERROR] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            print(f"  [ERROR] ì˜ˆì™¸: {e}")
            return None

    def run_analysis_evaluation(self, limit: Optional[int] = None, cleanup: bool = True):
        """ì´ë©”ì¼ ë¶„ì„ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print(f"ğŸ“Š ì´ë©”ì¼ ë¶„ì„ í‰ê°€ ì‹œì‘ (Phase: {self.phase})")
        print("=" * 60)

        dataset = self.load_test_data()
        ground_truths = self.load_ground_truth()

        emails = dataset["emails"]
        if limit:
            emails = emails[:limit]

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° DB ì‚½ì…
        emails = self.setup_test_data(emails)

        total = len(emails)
        success = 0
        failed = 0

        # Gemini ë¬´ë£Œ tier Rate Limit: ë¶„ë‹¹ 20íšŒ
        # ì•ˆì „í•˜ê²Œ 4ì´ˆ ë”œë ˆì´ (60ì´ˆ / 15íšŒ = 4ì´ˆ)
        REQUEST_DELAY = 4  # seconds
        RETRY_DELAY = 45  # seconds (Rate Limit ì—ëŸ¬ ì‹œ - ë„‰ë„‰í•˜ê²Œ)

        try:
            for i, email in enumerate(emails):
                synthetic_id = email["id"]  # ì›ë³¸ ID (synthetic_001)
                db_id = email["db_id"]  # DB ID (90001)

                print(f"\n[{i + 1}/{total}] ë¶„ì„ ì¤‘: {email['subject'][:40]}... (DB ID: {db_id})")

                # Rate Limit ë°©ì§€: ì²« ë²ˆì§¸ ìš”ì²­ ì´í›„ë¶€í„° ë”œë ˆì´ ì ìš©
                if i > 0:
                    print(f"  â³ Rate Limit ëŒ€ê¸° ì¤‘... ({REQUEST_DELAY}ì´ˆ)")
                    time.sleep(REQUEST_DELAY)

                # API í˜¸ì¶œ (ì‹¤íŒ¨ ì‹œ 1íšŒ ì¬ì‹œë„)
                ai_result = self.call_analyze_api(email)

                # ë¹ˆ ì‘ë‹µì´ë©´ Rate Limit ê°€ëŠ¥ì„± - ì¬ì‹œë„
                if ai_result is None:
                    print(f"  ğŸ”„ ì¬ì‹œë„ ì¤‘... ({RETRY_DELAY}ì´ˆ ëŒ€ê¸°)")
                    time.sleep(RETRY_DELAY)
                    ai_result = self.call_analyze_api(email)

                if ai_result and ai_result.get("success") is not False:
                    # Ground Truth ê°€ì ¸ì˜¤ê¸°
                    gt = ground_truths.get(synthetic_id, {})

                    # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
                    analysis = ai_result.get("analysis", {})

                    # í‰ê°€ ì‹¤í–‰
                    evaluation = self.evaluator.evaluate_analysis(
                        email_id=synthetic_id,
                        ai_result={
                            "email_type": analysis.get("email_type"),
                            "importance_score": analysis.get("importance_score"),
                            "needs_reply": analysis.get("needs_reply"),
                            "sentiment": analysis.get("sentiment")
                        },
                        ground_truth={
                            "email_type": gt.get("email_type"),
                            "importance_score": gt.get("importance_score"),
                            "needs_reply": gt.get("needs_reply"),
                            "sentiment": gt.get("sentiment")
                        }
                    )

                    self.results["analysis_results"].append({
                        "email_id": synthetic_id,
                        "db_id": db_id,
                        "subject": email["subject"],
                        "ai_result": analysis,
                        "ground_truth": gt,
                        "score": evaluation.total_score,
                        "notes": evaluation.evaluation_notes
                    })

                    success += 1
                    print(f"  âœ… ì ìˆ˜: {evaluation.total_score}/100 - {evaluation.evaluation_notes or 'OK'}")

                else:
                    failed += 1
                    self.results["errors"].append({
                        "email_id": synthetic_id,
                        "db_id": db_id,
                        "error": "API í˜¸ì¶œ ì‹¤íŒ¨"
                    })
                    print(f"  âŒ ì‹¤íŒ¨")

            # í†µê³„ ê³„ì‚°
            stats = self.evaluator.get_analysis_statistics()
            self.results["analysis_statistics"] = stats

            print("\n" + "-" * 60)
            print(f"ğŸ“ˆ ë¶„ì„ í‰ê°€ ì™„ë£Œ: ì„±ê³µ {success}/{total}, ì‹¤íŒ¨ {failed}")
            print(f"ğŸ“Š í‰ê·  ì ìˆ˜: {stats.get('average_score', 0)}ì ")
            print("-" * 60)

            return stats

        finally:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
            if cleanup:
                self.cleanup_test_data()

    def run_reply_evaluation(self, limit: Optional[int] = None, cleanup: bool = True):
        """ë‹µë³€ ìƒì„± ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print(f"âœï¸ ë‹µë³€ ìƒì„± í‰ê°€ ì‹œì‘ (Phase: {self.phase})")
        print("=" * 60)

        dataset = self.load_test_data()

        # needs_replyê°€ Trueì¸ ì´ë©”ì¼ë§Œ ì„ íƒ
        emails = [e for e in dataset["emails"] if e["ground_truth"].get("needs_reply")]
        if limit:
            emails = emails[:limit]

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° DB ì‚½ì… (ì•„ì§ ì•ˆí–ˆìœ¼ë©´)
        if not self.test_email_ids:
            emails = self.setup_test_data(emails)
        else:
            # ì´ë¯¸ ì‚½ì…ëœ ê²½ìš° db_id ë§¤í•‘
            for email in emails:
                if email["id"] in self.id_mapping:
                    email["db_id"] = self.id_mapping[email["id"]]

        total = len(emails)
        success = 0

        try:
            for i, email in enumerate(emails):
                synthetic_id = email["id"]
                db_id = email.get("db_id", self.id_mapping.get(synthetic_id))

                print(f"\n[{i + 1}/{total}] ë‹µë³€ ìƒì„± ì¤‘: {email['subject'][:40]}... (DB ID: {db_id})")

                # API í˜¸ì¶œ
                reply_result = self.call_reply_api(email)

                if reply_result and reply_result.get("success") is not False:
                    self.results["reply_results"].append({
                        "email_id": synthetic_id,
                        "db_id": db_id,
                        "subject": email["subject"],
                        "reply_drafts": reply_result.get("reply_drafts", {}),
                        "generated_at": datetime.now().isoformat()
                    })
                    success += 1
                    print(f"  âœ… 3ê°€ì§€ í†¤ ë‹µë³€ ìƒì„± ì™„ë£Œ")
                else:
                    print(f"  âŒ ì‹¤íŒ¨")

            print("\n" + "-" * 60)
            print(f"âœï¸ ë‹µë³€ ìƒì„± ì™„ë£Œ: ì„±ê³µ {success}/{total}")
            print("-" * 60)

        finally:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
            if cleanup:
                self.cleanup_test_data()

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        self.results["completed_at"] = datetime.now().isoformat()

        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        results_file = RESULTS_DIR / f"{self.phase}.json"
        results_file.parent.mkdir(parents=True, exist_ok=True)

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")

        return results_file

    def generate_report(self) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        stats = self.results.get("analysis_statistics", {})
        breakdown = stats.get("breakdown", {})

        report = f"""# ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸: {self.phase}

## ê°œìš”
- **í‰ê°€ ì¼ì‹œ**: {self.results.get('started_at', 'N/A')}
- **ì™„ë£Œ ì¼ì‹œ**: {self.results.get('completed_at', 'N/A')}
- **Phase**: {self.phase}

---

## ì´ë©”ì¼ ë¶„ì„ ì„±ëŠ¥

### ì „ì²´ í†µê³„
| í•­ëª© | ê°’ |
|------|-----|
| í‰ê°€ ê±´ìˆ˜ | {stats.get('count', 0)} |
| í‰ê·  ì ìˆ˜ | {stats.get('average_score', 0)}/100 |
| ì¤‘ì•™ê°’ | {stats.get('median_score', 0)} |
| ìµœì†Œ/ìµœëŒ€ | {stats.get('min_score', 0)} / {stats.get('max_score', 0)} |
| í‘œì¤€í¸ì°¨ | {stats.get('std_dev', 0)} |

### í•­ëª©ë³„ ì ìˆ˜ (25ì  ë§Œì )
| í•­ëª© | í‰ê·  ì ìˆ˜ | ì •í™•ë„ |
|------|----------|--------|
| email_type | {breakdown.get('email_type_avg', 0)} | {breakdown.get('email_type_avg', 0) / 25 * 100:.1f}% |
| importance_score | {breakdown.get('importance_avg', 0)} | {breakdown.get('importance_avg', 0) / 25 * 100:.1f}% |
| needs_reply | {breakdown.get('needs_reply_avg', 0)} | {breakdown.get('needs_reply_avg', 0) / 25 * 100:.1f}% |
| sentiment | {breakdown.get('sentiment_avg', 0)} | {breakdown.get('sentiment_avg', 0) / 25 * 100:.1f}% |

### ì‹œê°í™”
```
email_type      {'â–ˆ' * int(breakdown.get('email_type_avg', 0))}{'â–‘' * (25 - int(breakdown.get('email_type_avg', 0)))} {breakdown.get('email_type_avg', 0)}/25
importance      {'â–ˆ' * int(breakdown.get('importance_avg', 0))}{'â–‘' * (25 - int(breakdown.get('importance_avg', 0)))} {breakdown.get('importance_avg', 0)}/25
needs_reply     {'â–ˆ' * int(breakdown.get('needs_reply_avg', 0))}{'â–‘' * (25 - int(breakdown.get('needs_reply_avg', 0)))} {breakdown.get('needs_reply_avg', 0)}/25
sentiment       {'â–ˆ' * int(breakdown.get('sentiment_avg', 0))}{'â–‘' * (25 - int(breakdown.get('sentiment_avg', 0)))} {breakdown.get('sentiment_avg', 0)}/25
```

---

## ìƒì„¸ ê²°ê³¼

### ì˜¤ë¥˜ ë°œìƒ ê±´
"""
        if self.results.get("errors"):
            for error in self.results["errors"]:
                report += f"- `{error['email_id']}`: {error['error']}\n"
        else:
            report += "ì—†ìŒ\n"

        report += f"""
---

## ê°œì„  ì œì•ˆ

1. **email_type ì •í™•ë„ ê°œì„ **: {"í”„ë¡¬í”„íŠ¸ì— ë¶„ë¥˜ ì˜ˆì‹œ ì¶”ê°€ í•„ìš”" if breakdown.get('email_type_avg', 0) < 20 else "ì–‘í˜¸"}
2. **importance ì •í™•ë„ ê°œì„ **: {"ì¤‘ìš”ë„ ê¸°ì¤€ ëª…í™•í™” í•„ìš”" if breakdown.get('importance_avg', 0) < 20 else "ì–‘í˜¸"}
3. **sentiment ì •í™•ë„ ê°œì„ **: {"ê°ì • ë¶„ì„ í”„ë¡¬í”„íŠ¸ ë³´ê°• í•„ìš”" if breakdown.get('sentiment_avg', 0) < 20 else "ì–‘í˜¸"}

---

*Generated at {datetime.now().isoformat()}*
"""

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_dir = REPORTS_DIR / self.phase
        report_dir.mkdir(parents=True, exist_ok=True)
        report_file = report_dir / "analysis_report.md"

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"ğŸ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")

        return report


def compare_phases(phase1: str = "phase1_baseline", phase2: str = "phase2_with_rag"):
    """ë‘ Phase ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\n" + "=" * 60)
    print(f"ğŸ“Š Phase ë¹„êµ: {phase1} vs {phase2}")
    print("=" * 60)

    # ê²°ê³¼ ë¡œë“œ
    phase1_file = RESULTS_DIR / f"{phase1}.json"
    phase2_file = RESULTS_DIR / f"{phase2}.json"

    if not phase1_file.exists():
        print(f"âŒ {phase1} ê²°ê³¼ íŒŒì¼ ì—†ìŒ")
        return

    if not phase2_file.exists():
        print(f"âŒ {phase2} ê²°ê³¼ íŒŒì¼ ì—†ìŒ")
        return

    with open(phase1_file, 'r', encoding='utf-8') as f:
        p1_data = json.load(f)

    with open(phase2_file, 'r', encoding='utf-8') as f:
        p2_data = json.load(f)

    p1_stats = p1_data.get("analysis_statistics", {})
    p2_stats = p2_data.get("analysis_statistics", {})

    # ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±
    p1_avg = p1_stats.get('average_score', 0)
    p2_avg = p2_stats.get('average_score', 0)
    improvement = p2_avg - p1_avg
    improvement_pct = (improvement / p1_avg * 100) if p1_avg > 0 else 0

    comparison_report = f"""# Phase ë¹„êµ ë¦¬í¬íŠ¸

## ê°œìš”
- **Phase 1**: {phase1}
- **Phase 2**: {phase2}
- **ë¹„êµ ì¼ì‹œ**: {datetime.now().isoformat()}

---

## ì „ì²´ ì ìˆ˜ ë¹„êµ

| í•­ëª© | {phase1} | {phase2} | ë³€í™” |
|------|----------|----------|------|
| í‰ê·  ì ìˆ˜ | {p1_avg} | {p2_avg} | {improvement:+.1f} ({improvement_pct:+.1f}%) |
| í‰ê°€ ê±´ìˆ˜ | {p1_stats.get('count', 0)} | {p2_stats.get('count', 0)} | - |

---

## í•­ëª©ë³„ ë¹„êµ

| í•­ëª© | {phase1} | {phase2} | ë³€í™” |
|------|----------|----------|------|
"""

    p1_breakdown = p1_stats.get('breakdown', {})
    p2_breakdown = p2_stats.get('breakdown', {})

    for key in ['email_type_avg', 'importance_avg', 'needs_reply_avg', 'sentiment_avg']:
        p1_val = p1_breakdown.get(key, 0)
        p2_val = p2_breakdown.get(key, 0)
        diff = p2_val - p1_val
        comparison_report += f"| {key} | {p1_val} | {p2_val} | {diff:+.1f} |\n"

    comparison_report += f"""
---

## ì‹œê°í™”

### {phase1} (Baseline)
```
í‰ê· : {'â–ˆ' * int(p1_avg / 4)}{'â–‘' * (25 - int(p1_avg / 4))} {p1_avg}/100
```

### {phase2} (ê°œì„ )
```
í‰ê· : {'â–ˆ' * int(p2_avg / 4)}{'â–‘' * (25 - int(p2_avg / 4))} {p2_avg}/100
```

### ê°œì„ ìœ¨
```
{'ğŸ”º' if improvement > 0 else 'ğŸ”»'} {abs(improvement_pct):.1f}% {'í–¥ìƒ' if improvement > 0 else 'í•˜ë½'}
```

---

## ê²°ë¡ 

{"âœ… RAG ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤." if improvement > 0 else "âš ï¸ ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•©ë‹ˆë‹¤."}

*Generated at {datetime.now().isoformat()}*
"""

    # ë¹„êµ ë¦¬í¬íŠ¸ ì €ì¥
    comparison_file = REPORTS_DIR / "phase_comparison.md"
    with open(comparison_file, 'w', encoding='utf-8') as f:
        f.write(comparison_report)

    print(f"ğŸ“ ë¹„êµ ë¦¬í¬íŠ¸ ì €ì¥: {comparison_file}")
    print(comparison_report)


def cleanup_test_data():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬"""
    print("\nğŸ§¹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì¤‘...")
    db_manager = TestDatabaseManager()
    deleted = db_manager.cleanup_all_test_emails()
    print(f"âœ… ì™„ë£Œ: {deleted}ê°œ ì‚­ì œ")


def main():
    parser = argparse.ArgumentParser(description="AI ë©”ì¼ ë¹„ì„œ ì„±ëŠ¥ í‰ê°€")
    parser.add_argument(
        "--phase",
        choices=["phase1_baseline", "phase2_with_rag"],
        default="phase1_baseline",
        help="í‰ê°€ Phase ì„ íƒ"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="í‰ê°€í•  ì´ë©”ì¼ ìˆ˜ ì œí•œ"
    )
    parser.add_argument(
        "--analysis-only",
        action="store_true",
        help="ì´ë©”ì¼ ë¶„ì„ë§Œ í‰ê°€"
    )
    parser.add_argument(
        "--compare",
        action="store_true",
        help="Phase 1ê³¼ Phase 2 ë¹„êµ"
    )
    parser.add_argument(
        "--generate-data",
        action="store_true",
        help="í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ë§Œ ìˆ˜í–‰"
    )
    parser.add_argument(
        "--cleanup",
        action="store_true",
        help="í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ (DBì—ì„œ ì‚­ì œ)"
    )
    parser.add_argument(
        "--no-cleanup",
        action="store_true",
        help="í‰ê°€ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìœ ì§€ (ë””ë²„ê¹…ìš©)"
    )

    args = parser.parse_args()

    if args.generate_data:
        print("ğŸ“¦ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
        dataset_generator.save_test_dataset()
        dataset_generator.save_ground_truth()
        print("âœ… ì™„ë£Œ!")
        print(f"   - {DATA_DIR / 'test_dataset.json'}")
        print(f"   - {DATA_DIR / 'ground_truth.json'}")
        return

    if args.cleanup:
        cleanup_test_data()
        return

    if args.compare:
        compare_phases()
        return

    # í‰ê°€ ì‹¤í–‰
    runner = EvaluationRunner(phase=args.phase)

    # cleanup ì—¬ë¶€ ê²°ì •
    should_cleanup = not args.no_cleanup

    # ë¶„ì„ í‰ê°€
    runner.run_analysis_evaluation(limit=args.limit, cleanup=False)

    # ë‹µë³€ ìƒì„± í‰ê°€ (ì˜µì…˜)
    if not args.analysis_only:
        runner.run_reply_evaluation(limit=args.limit, cleanup=should_cleanup)
    elif should_cleanup:
        runner.cleanup_test_data()

    # ê²°ê³¼ ì €ì¥
    runner.save_results()

    # ë¦¬í¬íŠ¸ ìƒì„±
    runner.generate_report()

    print("\nâœ… í‰ê°€ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
